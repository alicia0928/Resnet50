{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGAM+9q6cjGHJvqT3vBz8P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alicia0928/Resnet50/blob/main/%EB%AA%A8%EB%8D%B8_%EB%B6%88%EB%9F%AC%EC%98%A4%EB%8A%94_%ED%95%A8%EC%88%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3-H3kxUrrNMf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms # 이미지 데이터 transform\n",
        "from torch.utils.data import DataLoader # 이미지 데이터 로더\n",
        "import os\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "  torch.cuda.manual_seed_all(777)"
      ],
      "metadata": {
        "id": "XD6Qpo1_rTcx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNdCWHgRrWDH",
        "outputId": "41b42bbc-f395-49e2-e6f9-aed653c30f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 경로 지정\n",
        "\n",
        "train_path = '/content/drive/MyDrive/파이토치/train'\n",
        "test_path = '/content/drive/MyDrive/파이토치/test'\n",
        "\n",
        "Dataset_path = '/content/drive/MyDrive/파이토치'\n",
        "\n",
        "cactus_dir = '/cactus/'\n",
        "dracaena_sanderiana_dir = '/dracaena_sanderiana/'\n",
        "monstera_dir = '/monstera/'\n",
        "rosemary_dir = '/rosemary/'"
      ],
      "metadata": {
        "id": "R9klIPLcrX_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import resnet\n",
        "\n",
        "from torchvision import models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "resnet50 = models.resnet50(pretrained=False).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNmXuFe1t2xD",
        "outputId": "ec3363a5-810f-4532-fa35-49e007d640d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet50.fc = nn.Linear(resnet50.fc.in_features, 4).to(device)"
      ],
      "metadata": {
        "id": "dun_IeInt5ns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader # 데이터 커스터마이징\n",
        "from PIL import Image # PIL = Python Image Library\n",
        "import cv2 # albumentation transform을 쓰려면 꼭 이 라이브러리를 이용\n",
        "import tensorflow as tf\n",
        "\n",
        "class inhovation_Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, file_path, mode, transform=None):\n",
        "    self.all_data = sorted(glob.glob(os.path.join(file_path, mode, '*', '*')))\n",
        "    self.transform = transform\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "\n",
        "    if torch.is_tensor(index):        # 인덱스가 tensor 형태일 수 있으니 리스트 형태로 바꿔준다.\n",
        "       index = index.tolist()\n",
        "\n",
        "    data_path = self.all_data[index]\n",
        "    img = np.array(Image.open(data_path).convert(\"RGB\")) # albumenatation transform을 쓰려면 cv2 라이브러리로 이미지를 읽어야 함\n",
        "    image=cv2.imread(data_path)\n",
        "    image=cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # BGR -> RGB 변환\n",
        "\n",
        "    # transform 적용\n",
        "    if self.transform is not None:\n",
        "       augmented = self.transform(image=image)\n",
        "       image = augmented['image']\n",
        "\n",
        "    # 이미지 이름을 활용해 label 부여\n",
        "    label=[]\n",
        "    if os.path.basename(data_path).startswith(\"cactus\") == True:\n",
        "        label = 0\n",
        "    elif os.path.basename(data_path).startswith(\"dracaena_sanderiana\") == True:\n",
        "        label = 1\n",
        "    elif os.path.basename(data_path).startswith(\"monstera\") == True:\n",
        "        label = 2\n",
        "    elif os.path.basename(data_path).startswith(\"rosemary\") == True:\n",
        "        label = 3\n",
        "    else :\n",
        "        label = 4\n",
        "    return image, label\n",
        "\n",
        "  def __len__(self):\n",
        "    length = len(self.all_data)\n",
        "    return length\n"
      ],
      "metadata": {
        "id": "PpJFjeZ7raI2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import resnet\n",
        "import torchvision.models.resnet as resnet\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# 미리 정의\n",
        "conv1x1=resnet.conv1x1\n",
        "Bottleneck = resnet.Bottleneck\n",
        "BasicBlock= resnet.BasicBlock"
      ],
      "metadata": {
        "id": "3JGe_dDUgc22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block, layers, num_classes=1000, zero_init_residual=True):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.inplanes = 32 # conv1에서 나올 채널의 차원 -> 이미지넷보다 작은 데이터이므로 32로 조정\n",
        "\n",
        "        # inputs = 3x224x224 -> 3x128x128로 바뀜\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False) # 마찬가지로 전부 사이즈 조정\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 32, layers[0], stride=1) # 3 반복\n",
        "        self.layer2 = self._make_layer(block, 64, layers[1], stride=2) # 4 반복\n",
        "        self.layer3 = self._make_layer(block, 128, layers[2], stride=2) # 6 반복\n",
        "        self.layer4 = self._make_layer(block, 256, layers[3], stride=2) # 3 반복\n",
        "\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.fc = nn.Linear(256 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "        # Zero-initialize the last BN in each residual branch,\n",
        "        # so that the residual branch starts with zeros, and each residual block behaves like an identity.\n",
        "        # This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677\n",
        "        if zero_init_residual:\n",
        "            for m in self.modules():\n",
        "                if isinstance(m, Bottleneck):\n",
        "                    nn.init.constant_(m.bn3.weight, 0)\n",
        "                elif isinstance(m, BasicBlock):\n",
        "                    nn.init.constant_(m.bn2.weight, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1): # planes -> 입력되는 채널 수\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                conv1x1(self.inplanes, planes * block.expansion, stride),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for _ in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # input [32, 128, 128] -> [C ,H, W]\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.maxpool(x)\n",
        "        #x.shape =[32, 64, 64]\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        #x.shape =[128, 64, 64]\n",
        "        x = self.layer2(x)\n",
        "        #x.shape =[256, 32, 32]\n",
        "        x = self.layer3(x)\n",
        "        #x.shape =[512, 16, 16]\n",
        "        x = self.layer4(x)\n",
        "        #x.shape =[1024, 8, 8]\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "f4NhEEctgfWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import albumentations\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "\n",
        "\n",
        "albumentations_resize = albumentations.Compose([\n",
        "\n",
        "    albumentations.Resize(128, 128),\n",
        "    ToTensorV2()\n",
        "\n",
        "])\n",
        "\n",
        "# resize_train=inhovation_Dataset(Dataset_path, 'train', transform=albumentations_resize)\n",
        "# resize_test=inhovation_Dataset(Dataset_path, 'test', transform=albumentations_resize)\n",
        "resize_test_mean=[0.15918699, 0.410329, 0.55247366]\n",
        "resize_test_std=[0.1542138, 0.16098696, 0.15552239]\n",
        "# # 이미지 전처리를 위한 변환 정의\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(resize_test_mean, resize_test_std)\n",
        "])\n",
        "\n",
        "\n",
        "# 이미지 불러오기\n",
        "image = Image.open('/content/drive/MyDrive/파이토치/model_test/test6.jpg')\n",
        "\n",
        "# 전처리 적용\n",
        "input_tensor = transform_test(image)  # 전처리된 이미지 텐서\n",
        "\n",
        "# 배치 차원 추가\n",
        "input_batch = input_tensor.unsqueeze(0)  # 배치 차원 추가\n",
        "\n",
        "# GPU 사용 가능 여부 확인 및 적용\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "input_batch = input_batch.to(device)\n",
        "\n",
        "# 모델 불러오기\n",
        "loaded_model = torch.load('/content/drive/MyDrive/파이토치/best_model.pth', map_location=torch.device('cpu'))\n",
        "\n",
        "\n",
        "# 모델을 평가 모드로 전환\n",
        "loaded_model.eval()\n",
        "\n",
        "# 모델에 입력 전달하여 출력 얻기\n",
        "with torch.no_grad():  # 그래디언트 계산 비활성화\n",
        "    output = loaded_model(input_batch)\n",
        "\n",
        "# 출력값 중 가장 높은 값을 갖는 클래스 선택\n",
        "_, predicted = torch.max(output, 1)\n",
        "\n",
        "# 선택된 클래스 출력\n",
        "print(\"예측된 클래스:\", predicted.item())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdF5Vfin-w5i",
        "outputId": "157d09e4-58b4-49e3-a4a8-8e089f45eda3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예측된 클래스: 2\n"
          ]
        }
      ]
    }
  ]
}